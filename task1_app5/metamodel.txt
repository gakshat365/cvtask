============================================================
MODEL METADATA
============================================================

MODEL NAME:
  3-Layer CNN for Colored MNIST Classification

MODEL ARCHITECTURE:
CNN3Layer(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool1): ChannelWiseMaxPool2d()
  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool2): ChannelWiseMaxPool2d()
  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool3): ChannelWiseMaxPool2d()
  (fc1): Linear(in_features=576, out_features=128, bias=True)
  (dropout): Dropout(p=0.0, inplace=False)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)

MODEL STRUCTURE:
  CHANNEL-WISE POOLING STRATEGY:
  - Using ChannelWiseMaxPool2d instead of standard MaxPool2d
  - Each color channel (R, G, B) is pooled INDEPENDENTLY
  - Preserves color information separately

  Layer 1: Conv2d(3 -> 32, kernel=3x3, padding=1) + ReLU + ChannelWiseMaxPool2d(2x2)
  Layer 2: Conv2d(32 -> 64, kernel=3x3, padding=1) + ReLU + ChannelWiseMaxPool2d(2x2)
  Layer 3: Conv2d(64 -> 64, kernel=3x3, padding=1) + ReLU + ChannelWiseMaxPool2d(2x2)
  FC Layer 1: Linear(576 -> 128) + ReLU + Dropout(0.5)
  FC Layer 2: Linear(128 -> 10)

TOTAL PARAMETERS:
  131,466

HYPERPARAMETERS:
  Epochs: 10
  Batch Size: 128
  Learning Rate: 0.01
  Optimizer: Adam
  Loss Function: CrossEntropyLoss
  Dropout Rate: 0.0
  Validation Split: 0.1 (10%)

INPUT SPECIFICATIONS:
  Input Shape: torch.Size([3, 28, 28])
  Number of Classes: 10
  Image Size: 28x28x3 (RGB)

TRAINING DATA:
  Training Samples: 54000
  Validation Samples: 6000

TEST DATASETS:
  rg95z: 10000 samples
  gr95z: 10000 samples
  gr95e: 10000 samples
  gr95m: 10000 samples
  gr95h: 10000 samples
  gr95vh: 10000 samples
  bw95z: 10000 samples
  bw100z: 10000 samples

FINAL TRAINING METRICS:
  Final Training Loss: 0.0254
  Final Training Accuracy: 99.40%
  Final Validation Loss: 0.0258
  Final Validation Accuracy: 99.45%

SAVED FILES:
  Model State Dict: task1_v2_model.pth
  Full Model: task1_v2_full_model.pth
  Training History: training_history.npz
  Metadata: metamodel.txt

============================================================
