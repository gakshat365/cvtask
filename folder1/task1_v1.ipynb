{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7cd23a0",
   "metadata": {},
   "source": [
    "# 3-Layer CNN for Colored MNIST Classification\n",
    "\n",
    "This notebook implements a 3-layer Convolutional Neural Network to train and test on the colored MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eda555d",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df584044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8621465f",
   "metadata": {},
   "source": [
    "## 2. Load Data from NPZ Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "428b4fc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'colored_data/train_data.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2793916597.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'colored_data/train_data.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'colored_data/train_data.npz'"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_data = np.load('colored_data/train_data.npz')\n",
    "X_train = train_data['images']\n",
    "y_train = train_data['labels']\n",
    "\n",
    "# Load test dataset 1\n",
    "test_data1 = np.load('colored_data/test_data.npz')\n",
    "X_test1 = test_data1['images']\n",
    "y_test1 = test_data1['labels']\n",
    "\n",
    "# Load test dataset 2\n",
    "test_data2 = np.load('data_gr/test_data.npz')\n",
    "X_test2 = test_data2['images']\n",
    "y_test2 = test_data2['labels']\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"\\nTest dataset 1 shape: {X_test1.shape}\")\n",
    "print(f\"Test dataset 1 labels shape: {y_test1.shape}\")\n",
    "print(f\"\\nTest dataset 2 shape: {X_test2.shape}\")\n",
    "print(f\"Test dataset 2 labels shape: {y_test2.shape}\")\n",
    "print(f\"\\nNumber of classes: {len(np.unique(y_train))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef109682",
   "metadata": {},
   "source": [
    "## 3. Preprocess and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67a741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to [0, 1]\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test1 = X_test1.astype('float32') / 255.0\n",
    "X_test2 = X_test2.astype('float32') / 255.0\n",
    "\n",
    "# Create validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors and change format from (N, H, W, C) to (N, C, H, W)\n",
    "X_train_tensor = torch.FloatTensor(X_train).permute(0, 3, 1, 2)\n",
    "X_val_tensor = torch.FloatTensor(X_val).permute(0, 3, 1, 2)\n",
    "X_test1_tensor = torch.FloatTensor(X_test1).permute(0, 3, 1, 2)\n",
    "X_test2_tensor = torch.FloatTensor(X_test2).permute(0, 3, 1, 2)\n",
    "\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "y_val_tensor = torch.LongTensor(y_val)\n",
    "y_test1_tensor = torch.LongTensor(y_test1)\n",
    "y_test2_tensor = torch.LongTensor(y_test2)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 128\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test1_dataset = TensorDataset(X_test1_tensor, y_test1_tensor)\n",
    "test2_dataset = TensorDataset(X_test2_tensor, y_test2_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test1_loader = DataLoader(test1_dataset, batch_size=batch_size, shuffle=False)\n",
    "test2_loader = DataLoader(test2_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training set: {X_train_tensor.shape}\")\n",
    "print(f\"Validation set: {X_val_tensor.shape}\")\n",
    "print(f\"Test set 1: {X_test1_tensor.shape}\")\n",
    "print(f\"Test set 2: {X_test2_tensor.shape}\")\n",
    "print(f\"Input shape: {X_train_tensor.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce1a887",
   "metadata": {},
   "source": [
    "## 4. Build the 3-Layer CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1ff416",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3Layer(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN3Layer, self).__init__()\n",
    "        \n",
    "        # First Convolutional Layer\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Second Convolutional Layer\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Third Convolutional Layer\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # First conv block\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        \n",
    "        # Second conv block\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Third conv block\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model and move to device\n",
    "model = CNN3Layer(num_classes=10).to(device)\n",
    "\n",
    "# Display model architecture\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3845e83",
   "metadata": {},
   "source": [
    "## 5. Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff1feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(f\"Optimizer: Adam\")\n",
    "print(f\"Loss function: CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b87db",
   "metadata": {},
   "source": [
    "## 6. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafaf88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "epochs = 10\n",
    "\n",
    "# Lists to store history\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "val_loss_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        train_total += target.size(0)\n",
    "        train_correct += (predicted == target).sum().item()\n",
    "    \n",
    "    # Calculate average training metrics\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_accuracy = train_correct / train_total\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            val_total += target.size(0)\n",
    "            val_correct += (predicted == target).sum().item()\n",
    "    \n",
    "    # Calculate average validation metrics\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "    \n",
    "    # Store history\n",
    "    train_loss_history.append(avg_train_loss)\n",
    "    train_acc_history.append(train_accuracy)\n",
    "    val_loss_history.append(avg_val_loss)\n",
    "    val_acc_history.append(val_accuracy)\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f'Epoch [{epoch+1}/{epochs}] - '\n",
    "          f'Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f} - '\n",
    "          f'Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be247e2",
   "metadata": {},
   "source": [
    "## 7. Evaluate on Test Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5200ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test dataset 1 (no learning - evaluation mode only)\n",
    "model.eval()\n",
    "test1_loss = 0.0\n",
    "test1_correct = 0\n",
    "test1_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test1_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        test1_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        test1_total += target.size(0)\n",
    "        test1_correct += (predicted == target).sum().item()\n",
    "\n",
    "avg_test1_loss = test1_loss / len(test1_loader)\n",
    "test1_accuracy = test1_correct / test1_total\n",
    "\n",
    "print(f\"\\nTest Dataset 1 Results:\")\n",
    "print(f\"Test Loss: {avg_test1_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test1_accuracy:.4f} ({test1_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf910b",
   "metadata": {},
   "source": [
    "## 8. Predictions and Visualization - Test Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f022f48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test dataset 1 (no learning)\n",
    "model.eval()\n",
    "test1_predictions = []\n",
    "test1_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test1_loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        test1_predictions.extend(predicted.cpu().numpy())\n",
    "        test1_targets.extend(target.numpy())\n",
    "\n",
    "predicted_classes_test1 = np.array(test1_predictions)\n",
    "y_test1_array = np.array(test1_targets)\n",
    "\n",
    "# Visualize some predictions from test dataset 1\n",
    "num_samples = 20\n",
    "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(num_samples):\n",
    "    img_display = X_test1[i]\n",
    "    \n",
    "    axes[i].imshow(img_display)\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    pred_label = predicted_classes_test1[i]\n",
    "    true_label = y_test1_array[i]\n",
    "    \n",
    "    color = 'green' if pred_label == true_label else 'red'\n",
    "    axes[i].set_title(f'Pred: {pred_label}\\nTrue: {true_label}', \n",
    "                      fontsize=10, color=color, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Test Dataset 1 - Sample Predictions (Green=Correct, Red=Incorrect)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "correct = np.sum(predicted_classes_test1 == y_test1_array)\n",
    "total = len(y_test1_array)\n",
    "print(f\"\\nTest Dataset 1 - Correct predictions: {correct}/{total} ({correct/total*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71a3ee",
   "metadata": {},
   "source": [
    "## 9. Evaluate on Test Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f489b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test dataset 2 (no learning - evaluation mode only)\n",
    "model.eval()\n",
    "test2_loss = 0.0\n",
    "test2_correct = 0\n",
    "test2_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test2_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        test2_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        test2_total += target.size(0)\n",
    "        test2_correct += (predicted == target).sum().item()\n",
    "\n",
    "avg_test2_loss = test2_loss / len(test2_loader)\n",
    "test2_accuracy = test2_correct / test2_total\n",
    "\n",
    "print(f\"\\nTest Dataset 2 Results:\")\n",
    "print(f\"Test Loss: {avg_test2_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test2_accuracy:.4f} ({test2_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f56c6d2",
   "metadata": {},
   "source": [
    "## 10. Predictions and Visualization - Test Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test dataset 2 (no learning)\n",
    "model.eval()\n",
    "test2_predictions = []\n",
    "test2_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test2_loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        test2_predictions.extend(predicted.cpu().numpy())\n",
    "        test2_targets.extend(target.numpy())\n",
    "\n",
    "predicted_classes_test2 = np.array(test2_predictions)\n",
    "y_test2_array = np.array(test2_targets)\n",
    "\n",
    "# Visualize some predictions from test dataset 2\n",
    "num_samples = 20\n",
    "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(num_samples):\n",
    "    img_display = X_test2[i]\n",
    "    \n",
    "    axes[i].imshow(img_display)\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    pred_label = predicted_classes_test2[i]\n",
    "    true_label = y_test2_array[i]\n",
    "    \n",
    "    color = 'green' if pred_label == true_label else 'red'\n",
    "    axes[i].set_title(f'Pred: {pred_label}\\nTrue: {true_label}', \n",
    "                      fontsize=10, color=color, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Test Dataset 2 - Sample Predictions (Green=Correct, Red=Incorrect)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "correct = np.sum(predicted_classes_test2 == y_test2_array)\n",
    "total = len(y_test2_array)\n",
    "print(f\"\\nTest Dataset 2 - Correct predictions: {correct}/{total} ({correct/total*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142da490",
   "metadata": {},
   "source": [
    "## 11. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f61bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Training vs Validation Accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc_history, label='Training Accuracy', marker='o')\n",
    "plt.plot(val_acc_history, label='Validation Accuracy', marker='s')\n",
    "plt.title('Epoch-wise Training vs Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Training vs Validation Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss_history, label='Training Loss', marker='o')\n",
    "plt.plot(val_loss_history, label='Validation Loss', marker='s')\n",
    "plt.title('Epoch-wise Training vs Validation Loss', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957a1574",
   "metadata": {},
   "source": [
    "## 12. Save the Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bdf5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "import os\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save complete model\n",
    "torch.save(model.state_dict(), 'task1_v1.pth')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# To load the model later:\n",
    "# model = CNN3Layer(num_classes=10)\n",
    "# model.load_state_dict(torch.load('task1_v1.pth'))\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c94da5",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c332f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get predictions on test set\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Display confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(10))\n",
    "disp.plot(cmap='Blues', ax=ax, values_format='d')\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print classification metrics per class\n",
    "print(\"\\nPer-class Accuracy:\")\n",
    "for i in range(10):\n",
    "    if cm[i].sum() > 0:\n",
    "        class_acc = cm[i, i] / cm[i].sum() * 100\n",
    "        print(f\"Digit {i}: {class_acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
