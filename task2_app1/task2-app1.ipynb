{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14744565,"sourceType":"datasetVersion","datasetId":9423325},{"sourceId":14760510,"sourceType":"datasetVersion","datasetId":9434511},{"sourceId":294612773,"sourceType":"kernelVersion"},{"sourceId":296080624,"sourceType":"kernelVersion"},{"sourceId":740453,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":564868,"modelId":577353},{"sourceId":744672,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":568438,"modelId":580771}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"id":"d15a535a-4c5e-4ca5-9a09-744943ddd45d","cell_type":"markdown","source":"Importing libs","metadata":{}},{"id":"f41f3ef3-2358-4491-ae9d-da24c0d1c812","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# 1. Define the exact architecture from your training notebook\nclass CNN3Layer(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CNN3Layer, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.fc1 = nn.Linear(64 * 3 * 3, 128)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = self.pool3(F.relu(self.conv3(x)))\n        x = x.view(-1, 64 * 3 * 3)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n# Setup device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T22:44:06.324359Z","iopub.execute_input":"2026-02-07T22:44:06.325143Z","iopub.status.idle":"2026-02-07T22:44:06.334289Z","shell.execute_reply.started":"2026-02-07T22:44:06.325106Z","shell.execute_reply":"2026-02-07T22:44:06.333495Z"}},"outputs":[],"execution_count":null},{"id":"babc2e6a-2d3c-482c-be32-fb951244d2a3","cell_type":"code","source":"# 2. Initialize and Load Weights\nmodel = CNN3Layer(num_classes=10).to(device)\n\n# Replace with the path to your .pth file from folder 2\nmodel_path = '/kaggle/input/task1app3models/pytorch/default/1/task1approach3sc1_modelv1.pth' \nmodel.load_state_dict(torch.load(model_path, map_location=device))\n\n# Set to evaluation mode and freeze weights\nmodel.eval()\nfor param in model.parameters():\n    param.requires_grad = False\n\nprint(\"Model loaded and frozen for analysis.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T22:44:06.335689Z","iopub.execute_input":"2026-02-07T22:44:06.335905Z","iopub.status.idle":"2026-02-07T22:44:06.359176Z","shell.execute_reply.started":"2026-02-07T22:44:06.335885Z","shell.execute_reply":"2026-02-07T22:44:06.358666Z"}},"outputs":[],"execution_count":null},{"id":"6f4eb385-94fc-4c4b-ba7a-58059137f9f9","cell_type":"code","source":"def visualize_neuron(target_layer, target_channel, iterations=150, lr=0.09):\n    # Create random noise as the starting \"canvas\"\n    #input_image = torch.randn(1, 3, 28, 28, device=device) \n    input_image = torch.zeros(1, 3, 28, 28, device=device) \n    input_image.requires_grad = True\n    \n    optimizer = optim.Adam([input_image], lr=lr)\n\n    for i in range(iterations):\n        optimizer.zero_grad()\n        \n        # Forward pass through selected layers\n        x = model.conv1(input_image)\n        if target_layer == 'conv1':\n            activation = x\n        else:\n            x = model.pool1(F.relu(x))\n            x = model.conv2(x)\n            if target_layer == 'conv2':\n                activation = x\n            else:\n                x = model.pool2(F.relu(x))\n                x = model.conv3(x)\n                activation = x\n\n        # TASK 2: Maximize the mean activation of the chosen channel\n        loss = -10-activation[0, target_channel].mean()\n        \n        loss.backward()\n        optimizer.step()\n        \n        # Keep pixels in the valid [0, 1] range\n        input_image.data.clamp_(0, 1)\n\n    # Return optimized image for plotting\n    return input_image.detach().cpu().squeeze().permute(1, 2, 0).numpy()\n\n# Example: Visualize the 5th channel of the final convolutional layer\nimg = visualize_neuron(target_layer='conv3', target_channel=5)\n\nplt.figure(figsize=(4, 4))\nplt.imshow(img)\nplt.axis('off')\nplt.title(\"Optimized Feature for Conv3 Channel 5\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T22:44:06.359927Z","iopub.execute_input":"2026-02-07T22:44:06.360211Z","iopub.status.idle":"2026-02-07T22:44:06.608279Z","shell.execute_reply.started":"2026-02-07T22:44:06.360191Z","shell.execute_reply":"2026-02-07T22:44:06.607598Z"}},"outputs":[],"execution_count":null},{"id":"f7cd6839-8db7-48b3-b706-b909b76b135b","cell_type":"code","source":"# Set the number of rows and columns for the grid\nrows, cols = 4, 16\nfig, axes = plt.subplots(rows, cols, figsize=(24, 6))\n\nprint(\"Generating visualizations for all 64 channels in conv3... This may take a few minutes.\")\n\nfor i in range(64):\n    # Calculate the row and column index for the current channel\n    r = i // cols\n    c = i % cols\n    \n    # Generate the optimized image for the specific channel\n    # We use fewer iterations (e.g., 100) to speed up the process for 64 images\n    img = visualize_neuron(target_layer='conv3', target_channel=i, iterations=100)\n    \n    # Display in the grid\n    axes[r, c].imshow(img)\n    axes[r, c].axis('off')\n    \n    # Optional: add small titles for identification\n    if r == 0:\n        axes[r, c].set_title(f\"Ch {i}\", fontsize=8)\n\nplt.tight_layout()\nplt.suptitle(\"Feature Visualizations for all 64 Channels of Conv3\", fontsize=16, y=1.05)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T22:44:06.609063Z","iopub.execute_input":"2026-02-07T22:44:06.609435Z","iopub.status.idle":"2026-02-07T22:44:15.777634Z","shell.execute_reply.started":"2026-02-07T22:44:06.609411Z","shell.execute_reply":"2026-02-07T22:44:15.777002Z"}},"outputs":[],"execution_count":null},{"id":"302d0464-8c47-4c8c-9c20-703b414cad5a","cell_type":"code","source":"def find_top_k_images(model, dataset_loader, target_layer, target_channel, k=10):\n    activations = []\n    images = []\n\n    model.eval()\n    with torch.no_grad():\n        for batch_images, _ in dataset_loader:\n            batch_images = batch_images.to(device)\n            \n            # Manual forward pass to intercept activation\n            x = model.conv1(batch_images)\n            if target_layer == 'conv1': act = x\n            else:\n                x = model.pool1(torch.relu(x))\n                x = model.conv2(x)\n                if target_layer == 'conv2': act = x\n                else:\n                    x = model.pool2(torch.relu(x))\n                    x = model.conv3(x)\n                    act = x\n            \n            # Get mean activation for the channel per image in batch\n            mean_act = act[:, target_channel].mean(dim=(1, 2)) \n            \n            activations.append(mean_act.cpu())\n            images.append(batch_images.cpu())\n\n    activations = torch.cat(activations)\n    images = torch.cat(images)\n    \n    # Get indices of top k activations\n    top_values, top_indices = torch.topk(activations, k)\n    \n    # Plot the results\n    fig, axes = plt.subplots(1, k, figsize=(15, 3))\n    for i in range(k):\n        img = images[top_indices[i]].permute(1, 2, 0).numpy()\n        axes[i].imshow(img)\n        axes[i].set_title(f\"Act: {top_values[i]:.2f}\")\n        axes[i].axis('off')\n    plt.suptitle(f\"Top {k} images for {target_layer} Channel {target_channel}\")\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T22:44:15.779007Z","iopub.execute_input":"2026-02-07T22:44:15.779313Z","iopub.status.idle":"2026-02-07T22:44:15.786977Z","shell.execute_reply.started":"2026-02-07T22:44:15.779282Z","shell.execute_reply":"2026-02-07T22:44:15.786388Z"}},"outputs":[],"execution_count":null},{"id":"e84a32ce-5f8f-4fd6-8d0b-0cbf7cf079ac","cell_type":"code","source":"# 1. Pick a neuron to investigate\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\n\n# 1. Load your data (ensure the .npz file path is correct)\ndata = np.load('/kaggle/input/cmnistneo1/test_data_rg100z.npz')\nX_train = data['images']\ny_train = data['labels']\n\n\n# 2. Normalize pixel values to [0, 1]\nX_train = X_train.astype('float32') / 255.0\n\n# 3. Create validation split (replicating your original 10% split)\n# The random_state=42 ensures you get the same validation set as your training\nX_train_split, X_val, y_train_split, y_val = train_test_split(\n    X_train, y_train, test_size=0.1, random_state=42\n)\n\n# 4. Convert to PyTorch tensors and permute format to (Batch, Channel, Height, Width)\nX_val_tensor = torch.FloatTensor(X_val).permute(0, 3, 1, 2)\ny_val_tensor = torch.LongTensor(y_val)\n\n# 5. Create the DataLoader\nbatch_size = 128\nval_dataset = TensorDataset(X_val_tensor, y_val_tensor)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\nprint(f\"Validation loader initialized with {len(val_dataset)} images.\")\nprint(f\"Tensor shape: {X_val_tensor.shape}\") # Should be (6000, 3, 28, 28)\n\ntarget_layer = 'conv3'\ntarget_ch = 2  # You can change this to 15, 42, etc.\n\n# 2. Call the Visualizer (The \"Eye Test\")\n# This creates the optimized image starting from black pixels\nprint(f\"Generating feature visualization for {target_layer} Channel {target_ch}...\")\noptimized_img = visualize_neuron(target_layer=target_layer, target_channel=target_ch, iterations=200)\n\n# 3. Call the Top-K Finder (The \"Dataset Test\")\n# This shows the actual images from your data that activate this neuron the most\n# Note: Ensure 'val_loader' from your Task 1 code is initialized!\nprint(f\"Finding top activating images from the dataset...\")\nfind_top_k_images(model, val_loader, target_layer=target_layer, target_channel=target_ch, k=10)\n\n# Display the optimized \"ideal\" image for comparison\nplt.figure(figsize=(4,4))\nplt.imshow(optimized_img)\nplt.title(f\"Optimized 'Ideal' Image\\n({target_layer} Ch {target_ch})\")\nplt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T22:44:15.787748Z","iopub.execute_input":"2026-02-07T22:44:15.787973Z","iopub.status.idle":"2026-02-07T22:44:16.700229Z","shell.execute_reply.started":"2026-02-07T22:44:15.787951Z","shell.execute_reply":"2026-02-07T22:44:16.699687Z"}},"outputs":[],"execution_count":null},{"id":"318d6627-000c-4878-a391-1fccd1bc72b6","cell_type":"code","source":"# Loop through all 64 channels of the final convolutional layer\nfor target_ch in range(64):\n    \n    # 1. Generate the optimized 'hallucination' (The Eye Test)\n    # We use 150 iterations to balance speed and quality for 64 channels\n    optimized_img = visualize_neuron(target_layer='conv3', target_channel=target_ch, iterations=150)\n\n    # 2. Find activations for this channel across the entire validation set\n    activations = []\n    images = []\n    model.eval()\n    with torch.no_grad():\n        for batch_images, _ in val_loader:\n            batch_images = batch_images.to(device)\n            \n            # Forward pass specifically to the target layer\n            x = model.conv1(batch_images)\n            x = model.pool1(torch.relu(x))\n            x = model.conv2(x)\n            x = model.pool2(torch.relu(x))\n            act = model.conv3(x)\n            \n            # Get mean activation for the specific channel\n            mean_act = act[:, target_ch].mean(dim=(1, 2)) \n            activations.append(mean_act.cpu())\n            images.append(batch_images.cpu())\n\n    activations = torch.cat(activations)\n    images = torch.cat(images)\n    \n    # Get indices of top 10 activations\n    top_values, top_indices = torch.topk(activations, 100)\n    \n    # 3. Plotting: [Ideal Image] followed by [Top 10 Dataset Images]\n    # Creating a grid of 1 row and 11 columns\n    fig, axes = plt.subplots(1, 11, figsize=(22, 2))\n    \n    # First slot: The Optimized Image\n    axes[0].imshow(optimized_img)\n    axes[0].set_title(f\"CH {target_ch} Ideal\", fontsize=10, fontweight='bold')\n    axes[0].axis('off')\n    \n    # Remaining 10 slots: Real images from the dataset\n    for i in range(10):\n        img = images[top_indices[i]].permute(1, 2, 0).numpy()\n        axes[i+1].imshow(img)\n        axes[i+1].set_title(f\"Act: {top_values[i]:.1f}\", fontsize=8)\n        axes[i+1].axis('off')\n\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T22:44:16.701257Z","iopub.execute_input":"2026-02-07T22:44:16.70163Z","iopub.status.idle":"2026-02-07T22:44:50.947056Z","shell.execute_reply.started":"2026-02-07T22:44:16.701606Z","shell.execute_reply":"2026-02-07T22:44:50.94626Z"}},"outputs":[],"execution_count":null}]}