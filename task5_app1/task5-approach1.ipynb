{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14760510,"sourceType":"datasetVersion","datasetId":9434511},{"sourceId":745111,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":568438,"modelId":580771}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# =========================================================\n# CONFIG\n# =========================================================\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nSOURCE_LABEL = 7\nTARGET_LABEL = 3\nEPSILON = 0.05\nNUM_SAMPLES = 500\n\nNUM_CLASSES = 10\nDROPOUT_RATE = 0.15\n\n# =========================================================\n# PATH HELPERS\n# =========================================================\ndef first_existing(paths):\n    for p in paths:\n        if os.path.exists(p):\n            return p\n    raise FileNotFoundError(\"Required file not found\")\n\nLAZY_MODEL_PATH = first_existing([\n    \"/kaggle/input/task1app3models/pytorch/default/2/task1approach3sc1_modelv2.pth\"\n])\n\nROBUST_MODEL_PATH = first_existing([\n    \"/kaggle/input/task1app3models/pytorch/default/2/task4_irm_modelv1.pth\"\n])\n\nTEST_DATA_PATH = first_existing([\n    \"/kaggle/input/cmnistneo1/test_data_gr100z.npz\"\n])\n\n# =========================================================\n# DATA STATS\n# =========================================================\ndef compute_dataset_stats(npz_path):\n    data = np.load(npz_path)\n    imgs = data[\"images\"].astype(np.float32) / 255.0\n\n    mean = imgs.mean(axis=(0, 1, 2))\n    std = imgs.std(axis=(0, 1, 2))\n\n    mean_t = torch.tensor(mean, device=DEVICE).view(3, 1, 1)\n    std_t = torch.tensor(std, device=DEVICE).view(3, 1, 1)\n\n    print(\"Dataset mean:\", mean.tolist())\n    print(\"Dataset std: \", std.tolist(), \"\\n\")\n\n    return mean_t, std_t\n\nMEAN, STD = compute_dataset_stats(TEST_DATA_PATH)\nLOWER = (0.0 - MEAN) / STD\nUPPER = (1.0 - MEAN) / STD\n\n# =========================================================\n# MODEL\n# =========================================================\nclass CNN3Layer(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n\n        self.pool = nn.MaxPool2d(2)\n        self.fc1 = nn.Linear(64 * 3 * 3, 128)\n        self.fc2 = nn.Linear(128, NUM_CLASSES)\n        self.dropout = nn.Dropout(DROPOUT_RATE)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = x.flatten(1)\n        x = self.dropout(F.relu(self.fc1(x)))\n        return self.fc2(x)\n\ndef load_model(path):\n    model = CNN3Layer().to(DEVICE)\n    state = torch.load(path, map_location=DEVICE)\n\n    if \"features.0.weight\" in state:\n        remap = {\n            \"features.0\": \"conv1\",\n            \"features.3\": \"conv2\",\n            \"features.6\": \"conv3\",\n            \"classifier.0\": \"fc1\",\n            \"classifier.3\": \"fc2\"\n        }\n        new_state = {}\n        for k, v in state.items():\n            for old, new in remap.items():\n                if k.startswith(old):\n                    k = k.replace(old, new)\n            new_state[k] = v\n        state = new_state\n\n    model.load_state_dict(state)\n    model.eval()\n    return model\n\n# =========================================================\n# FGSM (GENERATION)\n# =========================================================\n@torch.enable_grad()\ndef generate_fgsm(model, images, labels, epsilon, targeted=False):\n    images = images.clone().detach().requires_grad_(True)\n    logits = model(images)\n\n    if targeted:\n        targets = torch.full_like(labels, TARGET_LABEL)\n        loss = F.cross_entropy(logits, targets)\n        grad = torch.autograd.grad(loss, images)[0]\n        adv = images - epsilon * grad.sign()\n    else:\n        loss = F.cross_entropy(logits, labels)\n        grad = torch.autograd.grad(loss, images)[0]\n        adv = images + epsilon * grad.sign()\n\n    adv = torch.max(torch.min(adv, UPPER), LOWER)\n    return adv.detach(), grad.detach()\n\ndef attack_success(model, adv_images, labels, targeted=False):\n    with torch.no_grad():\n        preds = model(adv_images).argmax(dim=1)\n    if targeted:\n        return preds.eq(TARGET_LABEL).float().mean().item() * 100\n    else:\n        return (~preds.eq(labels)).float().mean().item() * 100\n\n# =========================================================\n# MAIN\n# =========================================================\nlazy_model = load_model(LAZY_MODEL_PATH)\nrobust_model = load_model(ROBUST_MODEL_PATH)\n\ndata = np.load(TEST_DATA_PATH)\n\nimages = torch.tensor(\n    data[\"images\"], dtype=torch.float32, device=DEVICE\n).permute(0, 3, 1, 2) / 255.0\n\nlabels = torch.tensor(data[\"labels\"], device=DEVICE)\n\nmask = labels == SOURCE_LABEL\nimages = ((images[mask][:NUM_SAMPLES]) - MEAN) / STD\nlabels = labels[mask][:NUM_SAMPLES]\n\n# ---- Generate adversarial examples ----\nlazy_adv, lazy_grad = generate_fgsm(lazy_model, images, labels, EPSILON, targeted=True)\nrobust_adv, robust_grad = generate_fgsm(robust_model, images, labels, EPSILON, targeted=True)\n\n# ---- Evaluate ----\nu_lazy = attack_success(lazy_model, lazy_adv, labels, targeted=False)\nu_robust = attack_success(robust_model, robust_adv, labels, targeted=False)\n\nt_lazy = attack_success(lazy_model, lazy_adv, labels, targeted=True)\nt_robust = attack_success(robust_model, robust_adv, labels, targeted=True)\n\nprint(\"=== FGSM Results ===\")\nprint(f\"Attack: {SOURCE_LABEL} → {TARGET_LABEL}\")\nprint(f\"Untargeted | Lazy: {u_lazy:.2f}% | Robust: {u_robust:.2f}%\")\nprint(f\"Targeted   | Lazy: {t_lazy:.2f}% | Robust: {t_robust:.2f}%\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-09T16:37:08.370504Z","iopub.execute_input":"2026-02-09T16:37:08.370919Z","iopub.status.idle":"2026-02-09T16:37:14.61064Z","shell.execute_reply.started":"2026-02-09T16:37:08.370884Z","shell.execute_reply":"2026-02-09T16:37:14.609823Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\n\n# =========================================================\n# DENORMALIZATION (shared)\n# =========================================================\ndef denormalize(x):\n    \"\"\"\n    x: (C,H,W) or (1,C,H,W) torch tensor in normalized space\n    returns: (H,W,C) numpy in [0,1]\n    \"\"\"\n    if x.dim() == 4:\n        x = x.squeeze(0)\n    img = torch.clamp(x * STD + MEAN, 0, 1)\n    return img.detach().cpu().permute(1, 2, 0).numpy()\n\n# =========================================================\n# FGSM GENERATION (MODEL-AGNOSTIC)\n# =========================================================\n@torch.enable_grad()\ndef generate_fgsm(model, images, labels, targeted=True):\n    \"\"\"\n    Generates adversarial images and input gradients for a given model.\n    Same function used for Lazy and IRM for fair comparison.\n    \"\"\"\n    images = images.clone().detach().requires_grad_(True)\n    logits = model(images)\n\n    if targeted:\n        targets = torch.full_like(labels, TARGET_LABEL)\n        loss = F.cross_entropy(logits, targets)\n        grad = torch.autograd.grad(loss, images)[0]\n        adv = images - EPSILON * grad.sign()\n    else:\n        loss = F.cross_entropy(logits, labels)\n        grad = torch.autograd.grad(loss, images)[0]\n        adv = images + EPSILON * grad.sign()\n\n    adv = torch.max(torch.min(adv, UPPER), LOWER)\n    return adv.detach(), grad.detach()\n\n# =========================================================\n# GENERATE ADVERSARIALS (ONCE)\n# =========================================================\nlazy_adv, lazy_grad = generate_fgsm(\n    lazy_model, images, labels, targeted=True\n)\n\nrobust_adv, robust_grad = generate_fgsm(\n    robust_model, images, labels, targeted=True\n)\n\n# =========================================================\n# VIS CONFIG\n# =========================================================\nN_VIZ = 8  # number of samples to visualize (same for all phases)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T16:37:14.612351Z","iopub.execute_input":"2026-02-09T16:37:14.612813Z","iopub.status.idle":"2026-02-09T16:37:14.625953Z","shell.execute_reply.started":"2026-02-09T16:37:14.612772Z","shell.execute_reply":"2026-02-09T16:37:14.625222Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axs = plt.subplots(3, N_VIZ, figsize=(18, 8))\n\nfor i in range(N_VIZ):\n    # Original\n    axs[0, i].imshow(denormalize(images[i]))\n    axs[0, i].axis(\"off\")\n\n    # Lazy model adversarial\n    axs[1, i].imshow(denormalize(lazy_adv[i]))\n    axs[1, i].axis(\"off\")\n\n    # IRM model adversarial\n    axs[2, i].imshow(denormalize(robust_adv[i]))\n    axs[2, i].axis(\"off\")\n\n# Row labels\naxs[0, 0].set_ylabel(\"Original\", fontsize=12)\naxs[1, 0].set_ylabel(\"Lazy (ERM)\", fontsize=12)\naxs[2, 0].set_ylabel(\"IRM (Robust)\", fontsize=12)\n\nplt.suptitle(\n    f\"Phase 0 — Original vs Adversarial (Lazy vs IRM) | ε = {EPSILON}\",\n    fontsize=14\n)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T16:37:14.627043Z","iopub.execute_input":"2026-02-09T16:37:14.627325Z","iopub.status.idle":"2026-02-09T16:37:14.993679Z","shell.execute_reply.started":"2026-02-09T16:37:14.627297Z","shell.execute_reply":"2026-02-09T16:37:14.992914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axs = plt.subplots(2, N_VIZ, figsize=(18, 5))\n\nfor i in range(N_VIZ):\n    orig = denormalize(images[i])\n\n    # Lazy perturbation\n    lazy_adv_img = denormalize(lazy_adv[i])\n    lazy_delta = np.abs(lazy_adv_img - orig)\n    lazy_delta_viz = np.clip(lazy_delta * 100, 0, 1)\n\n    # IRM perturbation\n    robust_adv_img = denormalize(robust_adv[i])\n    robust_delta = np.abs(robust_adv_img - orig)\n    robust_delta_viz = np.clip(robust_delta * 100, 0, 1)\n\n    axs[0, i].imshow(lazy_delta_viz)\n    axs[0, i].axis(\"off\")\n\n    axs[1, i].imshow(robust_delta_viz)\n    axs[1, i].axis(\"off\")\n\n# Row labels\naxs[0, 0].set_ylabel(\"|Δ| Lazy\", fontsize=12)\naxs[1, 0].set_ylabel(\"|Δ| IRM\", fontsize=12)\n\nplt.suptitle(\n    f\"Absolute Perturbation |Δ| (×100) | Lazy vs IRM | ε = {EPSILON}\",\n    fontsize=14\n)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T16:37:14.994602Z","iopub.execute_input":"2026-02-09T16:37:14.994874Z","iopub.status.idle":"2026-02-09T16:37:15.199415Z","shell.execute_reply.started":"2026-02-09T16:37:14.994852Z","shell.execute_reply":"2026-02-09T16:37:15.198826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axs = plt.subplots(2, N_VIZ, figsize=(18, 7))\n\nfor i in range(N_VIZ):\n    orig = denormalize(images[i])\n\n    # ----- Lazy model -----\n    lazy_adv_img = denormalize(lazy_adv[i])\n    lazy_delta = lazy_adv_img - orig\n    lazy_heat = np.linalg.norm(lazy_delta, axis=2)\n    lazy_heat = lazy_heat / (lazy_heat.max() + 1e-8)\n\n    axs[0, i].imshow(orig)\n    axs[0, i].imshow(lazy_heat, cmap=\"jet\", alpha=0.5)\n    axs[0, i].axis(\"off\")\n\n    # ----- IRM model -----\n    robust_adv_img = denormalize(robust_adv[i])\n    robust_delta = robust_adv_img - orig\n    robust_heat = np.linalg.norm(robust_delta, axis=2)\n    robust_heat = robust_heat / (robust_heat.max() + 1e-8)\n\n    axs[1, i].imshow(orig)\n    axs[1, i].imshow(robust_heat, cmap=\"jet\", alpha=0.5)\n    axs[1, i].axis(\"off\")\n\n# Row labels\naxs[0, 0].set_ylabel(\"Lazy (ERM)\", fontsize=12)\naxs[1, 0].set_ylabel(\"IRM (Robust)\", fontsize=12)\n\nplt.suptitle(\n    f\"Spatial Perturbation Heatmap | Lazy vs IRM | ε = {EPSILON}\",\n    fontsize=14\n)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T16:37:15.200174Z","iopub.execute_input":"2026-02-09T16:37:15.200389Z","iopub.status.idle":"2026-02-09T16:37:15.596235Z","shell.execute_reply.started":"2026-02-09T16:37:15.200369Z","shell.execute_reply":"2026-02-09T16:37:15.595628Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def collect_deltas(orig, adv):\n    return (adv - orig).reshape(-1)\n\nlazy_deltas = []\nrobust_deltas = []\n\nfor i in range(len(images)):\n    orig = denormalize(images[i])\n\n    lazy_adv_img = denormalize(lazy_adv[i])\n    robust_adv_img = denormalize(robust_adv[i])\n\n    lazy_deltas.append(collect_deltas(orig, lazy_adv_img))\n    robust_deltas.append(collect_deltas(orig, robust_adv_img))\n\nlazy_deltas = np.concatenate(lazy_deltas)\nrobust_deltas = np.concatenate(robust_deltas)\n\n# Symmetric range for fair comparison\nmax_range = max(\n    np.abs(lazy_deltas).max(),\n    np.abs(robust_deltas).max()\n)\n\nbins = np.linspace(-max_range, max_range, 200)\n\nplt.figure(figsize=(8, 5))\nplt.hist(\n    lazy_deltas, bins=bins, alpha=0.6,\n    label=\"Lazy (ERM)\", density=True\n)\nplt.hist(\n    robust_deltas, bins=bins, alpha=0.6,\n    label=\"IRM (Robust)\", density=True\n)\n\nplt.xlabel(\"Perturbation value (signed)\")\nplt.ylabel(\"Density\")\nplt.title(f\"Perturbation Value Distribution | ε = {EPSILON}\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T16:37:15.597121Z","iopub.execute_input":"2026-02-09T16:37:15.597323Z","iopub.status.idle":"2026-02-09T16:37:16.356741Z","shell.execute_reply.started":"2026-02-09T16:37:15.597304Z","shell.execute_reply":"2026-02-09T16:37:16.3558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axs = plt.subplots(4, N_VIZ, figsize=(18, 12))\n\nfor i in range(N_VIZ):\n    orig = denormalize(images[i])\n\n    # ===== Lazy model =====\n    lazy_grad_img = lazy_grad[i].detach().cpu().permute(1, 2, 0).numpy()\n    lazy_grad_mag = np.linalg.norm(lazy_grad_img, axis=2)\n\n    lazy_adv_img = denormalize(lazy_adv[i])\n    lazy_delta_mag = np.linalg.norm(lazy_adv_img - orig, axis=2)\n\n    axs[0, i].imshow(lazy_grad_mag, cmap=\"magma\")\n    axs[0, i].axis(\"off\")\n\n    axs[1, i].imshow(lazy_delta_mag, cmap=\"inferno\")\n    axs[1, i].axis(\"off\")\n\n    # ===== IRM model =====\n    robust_grad_img = robust_grad[i].detach().cpu().permute(1, 2, 0).numpy()\n    robust_grad_mag = np.linalg.norm(robust_grad_img, axis=2)\n\n    robust_adv_img = denormalize(robust_adv[i])\n    robust_delta_mag = np.linalg.norm(robust_adv_img - orig, axis=2)\n\n    axs[2, i].imshow(robust_grad_mag, cmap=\"magma\")\n    axs[2, i].axis(\"off\")\n\n    axs[3, i].imshow(robust_delta_mag, cmap=\"inferno\")\n    axs[3, i].axis(\"off\")\n\n# Row labels\naxs[0, 0].set_ylabel(\"‖∇x L‖\\nLazy\", fontsize=12)\naxs[1, 0].set_ylabel(\"‖Δ‖\\nLazy\", fontsize=12)\naxs[2, 0].set_ylabel(\"‖∇x L‖\\nIRM\", fontsize=12)\naxs[3, 0].set_ylabel(\"‖Δ‖\\nIRM\", fontsize=12)\n\nplt.suptitle(\n    f\"Gradients(what model is sensitive to) vs Perturbations(what model changed) | Lazy vs IRM | ε = {EPSILON}\",\n    fontsize=14\n)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T16:37:16.358777Z","iopub.execute_input":"2026-02-09T16:37:16.359043Z","iopub.status.idle":"2026-02-09T16:37:17.070971Z","shell.execute_reply.started":"2026-02-09T16:37:16.359012Z","shell.execute_reply":"2026-02-09T16:37:17.070291Z"}},"outputs":[],"execution_count":null}]}