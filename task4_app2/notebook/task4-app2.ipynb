{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14760510,"sourceType":"datasetVersion","datasetId":9434511},{"sourceId":745111,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":568438,"modelId":580771}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport os\nfrom itertools import cycle\n\n# ==============================================================================\n# Configuration & Hyperparameters\n# ==============================================================================\nclass Config:\n    # Data Paths\n    DATA_DIR = r\"/kaggle/input/cmnistneo1\"\n    TRAIN_FILE = \"train_data_rg95z.npz\"\n    TEST_FILE = \"test_data_gr95z.npz\"\n    \n    # Training Hyperparameters\n    BATCH_SIZE = 128\n    EPOCHS = 20\n    LR = 1e-3\n    WEIGHT_DECAY = 1e-4\n    \n    # REx Specifics\n    REX_PENALTY_WEIGHT = 100.0\n    REX_ANNEAL_EPOCHS = 5  # Epochs before penalty kicks in\n    \n    # System\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    SEED = 42\n\n# ==============================================================================\n# Model Architecture\n# ==============================================================================\nclass CNN3Layer(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CNN3Layer, self).__init__()\n        \n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            \n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            \n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2)\n        )\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(64 * 3 * 3, 128),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(128, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.reshape(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n# ==============================================================================\n# Utils: REx Penalty & Data Loading\n# ==============================================================================\ndef get_dominant_color(img_tensor):\n    \"\"\"Returns dominant channel index (0=R, 1=G, 2=B) for a single image tensor.\"\"\"\n    means = torch.mean(img_tensor, dim=(1, 2))\n    return torch.argmax(means).item()\n\ndef load_data(config):\n    \"\"\"Loads data and splits training set into two REx environments.\"\"\"\n    print(f\"\\n[Data] Loading from {config.DATA_DIR}...\")\n    \n    train_path = os.path.join(config.DATA_DIR, config.TRAIN_FILE)\n    if not os.path.exists(train_path):\n        raise FileNotFoundError(f\"Train file not found: {train_path}\")\n\n    # Load Train (Biased)\n    train_data = np.load(train_path)\n    X_train = torch.tensor(train_data['images'].astype('float32') / 255.0).permute(0, 3, 1, 2)\n    y_train = torch.tensor(train_data['labels']).long()\n\n    # 1. Identify Spurious Correlation (Color Bias)\n    print(\"[Data] Analyzing bias...\")\n    digit_bias_color = {}\n    for d in range(10):\n        indices = (y_train == d).nonzero(as_tuple=True)[0][:100]\n        colors = [get_dominant_color(X_train[i]) for i in indices]\n        majority = max(set(colors), key=colors.count)\n        digit_bias_color[d] = majority\n    \n    # 2. Split into Environments (Aligned vs Conflict)\n    img_means = torch.mean(X_train, dim=(2, 3))\n    img_colors = torch.argmax(img_means, dim=1)\n    \n    expected_colors = torch.tensor([digit_bias_color[y.item()] for y in y_train], device=X_train.device)\n    aligned_mask = (img_colors == expected_colors.cpu())\n    \n    env1_idx = torch.nonzero(aligned_mask, as_tuple=True)[0]\n    env2_idx = torch.nonzero(~aligned_mask, as_tuple=True)[0]\n    \n    print(f\"  Env 1 (Aligned/Biased): {len(env1_idx)} samples\")\n    print(f\"  Env 2 (Conflict/OOD):   {len(env2_idx)} samples\")\n\n    # Load Test (Hard OOD)\n    test_path = os.path.join(config.DATA_DIR, config.TEST_FILE)\n    test_data = np.load(test_path)\n    X_test = torch.tensor(test_data['images'].astype('float32') / 255.0).permute(0, 3, 1, 2)\n    y_test = torch.tensor(test_data['labels']).long()\n    \n    # Create Datasets\n    ds_env1 = TensorDataset(X_train[env1_idx], y_train[env1_idx])\n    ds_env2 = TensorDataset(X_train[env2_idx], y_train[env2_idx])\n    ds_test = TensorDataset(X_test, y_test)\n    \n    return ds_env1, ds_env2, ds_test\n\n# ==============================================================================\n# Training Loop with REx\n# ==============================================================================\ndef train(config):\n    torch.manual_seed(config.SEED)\n    \n    # Load Data\n    ds_env1, ds_env2, ds_test = load_data(config)\n    \n    # Loaders\n    loader1 = DataLoader(ds_env1, batch_size=config.BATCH_SIZE, shuffle=True)\n    loader2 = DataLoader(ds_env2, batch_size=config.BATCH_SIZE, shuffle=True)\n    loader_test = DataLoader(ds_test, batch_size=config.BATCH_SIZE, shuffle=False)\n    \n    # Env 2 is smaller (5%), so we cycle it to match Env 1 iterations\n    iter2 = cycle(loader2)\n    \n    # Model & Optim\n    model = CNN3Layer().to(config.DEVICE)\n    optimizer = optim.Adam(model.parameters(), lr=config.LR, weight_decay=config.WEIGHT_DECAY)\n    \n    print(f\"\\n[Train] Starting REx Training on {config.DEVICE}...\")\n    print(f\"  Penalty: {config.REX_PENALTY_WEIGHT} (Annealed for {config.REX_ANNEAL_EPOCHS} epochs)\")\n    \n    # Track history for plotting\n    history = {'loss': [], 'penalty': [], 'test_acc': []}\n    \n    for epoch in range(config.EPOCHS):\n        model.train()\n        total_loss = 0\n        total_penalty = 0\n        correct = 0\n        total = 0\n        \n        for x1, y1 in loader1:\n            x2, y2 = next(iter2)\n            \n            x1, y1 = x1.to(config.DEVICE), y1.to(config.DEVICE)\n            x2, y2 = x2.to(config.DEVICE), y2.to(config.DEVICE)\n            \n            # Forward\n            logits1 = model(x1)\n            logits2 = model(x2)\n            \n            # 1. Compute losses per environment\n            loss1 = nn.CrossEntropyLoss()(logits1, y1)\n            loss2 = nn.CrossEntropyLoss()(logits2, y2)\n            \n            # 2. REx: Mean + Variance penalty\n            mean_loss = (loss1 + loss2) / 2\n            \n            # Variance of losses across environments\n            penalty = torch.tensor(0.).to(config.DEVICE)\n            if epoch >= config.REX_ANNEAL_EPOCHS:\n                variance = ((loss1 - mean_loss) ** 2 + (loss2 - mean_loss) ** 2) / 2\n                penalty = variance\n            \n            # Total Loss: Mean(Losses) + beta * Variance(Losses)\n            weight = config.REX_PENALTY_WEIGHT if epoch >= config.REX_ANNEAL_EPOCHS else 0.0\n            total_loss_batch = mean_loss + weight * penalty\n            \n            optimizer.zero_grad()\n            total_loss_batch.backward()\n            optimizer.step()\n            \n            # Stats\n            total_loss += mean_loss.item()\n            total_penalty += penalty.item()\n            _, preds = torch.max(logits1, 1)\n            correct += (preds == y1).sum().item()\n            total += y1.size(0)\n            \n        # Logging\n        avg_risk = total_loss / len(loader1)\n        avg_penalty = total_penalty / len(loader1)\n        train_acc = 100 * correct / total\n        \n        # Evaluate on test set\n        val_acc = evaluate(model, loader_test, config.DEVICE)\n        \n        # Store history\n        history['loss'].append(avg_risk)\n        history['penalty'].append(avg_penalty)\n        history['test_acc'].append(val_acc)\n        \n        print(f\"Epoch [{epoch+1}/{config.EPOCHS}] Risk: {avg_risk:.4f} | Variance: {avg_penalty:.6f} | Train Acc: {train_acc:.1f}% | Test Acc: {val_acc:.2f}%\")\n\n    # Final Save\n    save_path = \"task4_rex_model.pth\"\n    torch.save(model.state_dict(), save_path)\n    print(f\"\\n[Done] Model saved to {save_path}\")\n    \n    # ========== VISUALIZATIONS ==========\n    print(\"\\n[Visualizations] Generating plots...\")\n    \n    # 1. Training History Plots\n    plt.figure(figsize=(15, 4))\n    \n    plt.subplot(1, 3, 1)\n    plt.plot(history['loss'], label='CE Loss', linewidth=2)\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training Loss (REx)')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    plt.subplot(1, 3, 2)\n    plt.plot(history['penalty'], label='Variance Penalty', color='orange', linewidth=2)\n    plt.axvline(config.REX_ANNEAL_EPOCHS, color='r', linestyle='--', alpha=0.5, label='Penalty Start')\n    plt.xlabel('Epoch')\n    plt.ylabel('Variance')\n    plt.title('REx Variance Penalty')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    plt.subplot(1, 3, 3)\n    plt.plot(history['test_acc'], label='Hard Test Acc', color='green', linewidth=2)\n    plt.axhline(70, color='r', linestyle='--', alpha=0.7, label='Target (70%)')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.title('Performance on Hard Test Set')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig('task4_rex_training.png', dpi=150, bbox_inches='tight')\n    print(\"  Saved: task4_rex_training.png\")\n    plt.show()\n    \n    # 2. Confusion Matrix\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for x, y in loader_test:\n            x, y = x.to(config.DEVICE), y.to(config.DEVICE)\n            out = model(x)\n            preds = torch.max(out, 1)[1]\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(y.cpu().numpy())\n    \n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix - REx on Hard Test Set')\n    plt.savefig('task4_rex_confusion.png', dpi=150, bbox_inches='tight')\n    print(\"  Saved: task4_rex_confusion.png\")\n    plt.show()\n    \n    # 3. Sample Predictions\n    test_data = np.load(os.path.join(config.DATA_DIR, config.TEST_FILE))\n    X_test_np = test_data['images']\n    y_test_np = test_data['labels']\n    \n    model.eval()\n    sample_indices = np.random.choice(len(X_test_np), 10, replace=False)\n    \n    plt.figure(figsize=(15, 6))\n    for i, idx in enumerate(sample_indices):\n        img_tensor = torch.FloatTensor(X_test_np[idx:idx+1] / 255.0).permute(0, 3, 1, 2).to(config.DEVICE)\n        with torch.no_grad():\n            pred = torch.max(model(img_tensor), 1)[1].item()\n        true_label = y_test_np[idx]\n        \n        plt.subplot(2, 5, i+1)\n        plt.imshow(X_test_np[idx])\n        plt.title(f'True: {true_label}\\nPred: {pred}', \n                 color='green' if pred == true_label else 'red')\n        plt.axis('off')\n    \n    plt.suptitle('REx: Sample Predictions on Hard Test Set', fontsize=14, y=1.02)\n    plt.tight_layout()\n    plt.savefig('task4_rex_samples.png', dpi=150, bbox_inches='tight')\n    print(\"  Saved: task4_rex_samples.png\")\n    plt.show()\n    \n    # 4. Final Summary\n    final_acc = history['test_acc'][-1]\n    print(f\"\\n{'='*60}\")\n    print(f\"FINAL RESULTS - Risk Extrapolation (REx)\")\n    print(f\"{'='*60}\")\n    print(f\"Final Test Accuracy: {final_acc:.2f}%\")\n    print(f\"Target Achieved: {'✓ YES' if final_acc >= 70 else '✗ NO'}\")\n    print(f\"Best Test Accuracy: {max(history['test_acc']):.2f}% (Epoch {np.argmax(history['test_acc'])+1})\")\n    print(f\"{'='*60}\")\n\ndef evaluate(model, loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            out = model(x)\n            _, preds = torch.max(out, 1)\n            correct += (preds == y).sum().item()\n            total += y.size(0)\n    return 100 * correct / total\n\nif __name__ == \"__main__\":\n    train(Config)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}