{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14760510,"sourceType":"datasetVersion","datasetId":9434511},{"sourceId":745111,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":568438,"modelId":580771}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n\n# =========================================================\n# CONFIG\n# =========================================================\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nSOURCE_LABEL = 7\nTARGET_LABEL = 3\nEPSILON = 0.05\nNUM_SAMPLES = 500\n\nNUM_CLASSES = 10\nDROPOUT_RATE = 0.15\n\n# =========================================================\n# PATH HELPERS\n# =========================================================\ndef first_existing(paths):\n    for p in paths:\n        if os.path.exists(p):\n            return p\n    raise FileNotFoundError(\"Required file not found\")\n\nLAZY_MODEL_PATH = first_existing([\n    \"/kaggle/input/task1app3models/pytorch/default/2/task1approach3sc1_modelv2.pth\"\n])\n\nROBUST_MODEL_PATH = first_existing([\n    \"/kaggle/input/task1app3models/pytorch/default/2/task4_irm_modelv1.pth\"\n])\n\nTEST_DATA_PATH = first_existing([\n    \"/kaggle/input/cmnistneo1/test_data_gr100z.npz\"\n])\n\n# =========================================================\n# DATA STATS\n# =========================================================\ndef compute_dataset_stats(npz_path):\n    data = np.load(npz_path)\n    imgs = data[\"images\"].astype(np.float32) / 255.0\n\n    mean = imgs.mean(axis=(0, 1, 2))\n    std = imgs.std(axis=(0, 1, 2))\n\n    mean_t = torch.tensor(mean, device=DEVICE).view(3, 1, 1)\n    std_t = torch.tensor(std, device=DEVICE).view(3, 1, 1)\n\n    print(\"Dataset mean:\", mean.tolist())\n    print(\"Dataset std: \", std.tolist(), \"\\n\")\n\n    return mean_t, std_t\n\nMEAN, STD = compute_dataset_stats(TEST_DATA_PATH)\nLOWER = (0.0 - MEAN) / STD\nUPPER = (1.0 - MEAN) / STD\n\n# =========================================================\n# MODEL\n# =========================================================\nclass CNN3Layer(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n\n        self.pool = nn.MaxPool2d(2)\n        self.fc1 = nn.Linear(64 * 3 * 3, 128)\n        self.fc2 = nn.Linear(128, NUM_CLASSES)\n        self.dropout = nn.Dropout(DROPOUT_RATE)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = x.flatten(1)\n        x = self.dropout(F.relu(self.fc1(x)))\n        return self.fc2(x)\n\ndef load_model(path):\n    model = CNN3Layer().to(DEVICE)\n    state = torch.load(path, map_location=DEVICE)\n\n    if \"features.0.weight\" in state:\n        remap = {\n            \"features.0\": \"conv1\",\n            \"features.3\": \"conv2\",\n            \"features.6\": \"conv3\",\n            \"classifier.0\": \"fc1\",\n            \"classifier.3\": \"fc2\"\n        }\n        new_state = {}\n        for k, v in state.items():\n            for old, new in remap.items():\n                if k.startswith(old):\n                    k = k.replace(old, new)\n            new_state[k] = v\n        state = new_state\n\n    model.load_state_dict(state)\n    model.eval()\n    return model\n\ndef attack_success(model, adv_images, labels, targeted=False):\n    with torch.no_grad():\n        preds = model(adv_images).argmax(dim=1)\n\n    if targeted:\n        return preds.eq(TARGET_LABEL).float().mean().item() * 100\n    else:\n        return (~preds.eq(labels)).float().mean().item() * 100\n\n\n# =========================================================\n# C&W (L2) HYPERPARAMETERS\n# =========================================================\nCW_STEPS = 1000\nCW_LR = 1e-2\nCW_C = 1.0\nCW_CONFIDENCE = 0.0   # κ in the C&W paper\n\n# =========================================================\n# C&W (GENERATION)\n# =========================================================\n@torch.enable_grad()\ndef generate_cw(model, images, labels, targeted=True):\n    \"\"\"\n    Targeted Carlini & Wagner (L2) attack.\n    Returns adversarial images and final-step gradients.\n    \"\"\"\n    model.eval()\n\n    # ---- inverse tanh space ----\n    clipped = torch.clamp(\n        images,\n        min=LOWER + 1e-6,\n        max=UPPER - 1e-6\n    )\n    w = torch.atanh((clipped - LOWER) / (UPPER - LOWER) * 2 - 1)\n    w = w.clone().detach().requires_grad_(True)\n\n    optimizer = torch.optim.Adam([w], lr=CW_LR)\n\n    target_labels = torch.full_like(labels, TARGET_LABEL, dtype=torch.long)\n\n\n\n    for _ in range(CW_STEPS):\n        adv = LOWER + (UPPER - LOWER) * (torch.tanh(w) + 1) / 2\n\n        logits = model(adv)\n\n        # ---- C&W loss ----\n        real = logits.gather(1, target_labels.unsqueeze(1)).squeeze(1)\n        other, _ = torch.max(\n            torch.where(\n                torch.eye(NUM_CLASSES, device=DEVICE)[target_labels] == 0,\n                logits,\n                torch.full_like(logits, -1e4),\n            ),\n            dim=1,\n        )\n\n        if targeted:\n            f_loss = torch.clamp(other - real + CW_CONFIDENCE, min=0)\n        else:\n            f_loss = torch.clamp(real - other + CW_CONFIDENCE, min=0)\n\n        l2_loss = torch.sum((adv - images) ** 2, dim=(1, 2, 3))\n        loss = torch.mean(l2_loss + CW_C * f_loss)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    # ---- final adversarial ----\n    adv = LOWER + (UPPER - LOWER) * (torch.tanh(w) + 1) / 2\n\n    # ---- gradient for Phase 6 ----\n    adv.requires_grad_(True)\n    logits = model(adv)\n    loss = F.cross_entropy(logits, target_labels)\n    grad = torch.autograd.grad(loss, adv)[0]\n\n    return adv.detach(), grad.detach()\n\n# =========================================================\n# MAIN (UNCHANGED EXCEPT ATTACK)\n# =========================================================\nlazy_model = load_model(LAZY_MODEL_PATH)\nrobust_model = load_model(ROBUST_MODEL_PATH)\n\ndata = np.load(TEST_DATA_PATH)\n\nimages = torch.tensor(\n    data[\"images\"], dtype=torch.float32, device=DEVICE\n).permute(0, 3, 1, 2) / 255.0\n\nlabels = torch.tensor(data[\"labels\"], device=DEVICE)\n\nmask = labels == SOURCE_LABEL\nimages = ((images[mask][:NUM_SAMPLES]) - MEAN) / STD\nlabels = labels[mask][:NUM_SAMPLES]\n\n# ---- Generate adversarial examples (C&W) ----\nlazy_adv, lazy_grad = generate_cw(\n    lazy_model, images, labels, targeted=True\n)\nrobust_adv, robust_grad = generate_cw(\n    robust_model, images, labels, targeted=True\n)\n\n# ---- Evaluate ----\nu_lazy = attack_success(lazy_model, lazy_adv, labels, targeted=False)\nu_robust = attack_success(robust_model, robust_adv, labels, targeted=False)\n\nt_lazy = attack_success(lazy_model, lazy_adv, labels, targeted=True)\nt_robust = attack_success(robust_model, robust_adv, labels, targeted=True)\n\nprint(\"=== C&W Results ===\")\nprint(f\"Attack: {SOURCE_LABEL} → {TARGET_LABEL}\")\nprint(f\"Untargeted | Lazy: {u_lazy:.2f}% | Robust: {u_robust:.2f}%\")\nprint(f\"Targeted   | Lazy: {t_lazy:.2f}% | Robust: {t_robust:.2f}%\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-09T17:10:14.378406Z","iopub.execute_input":"2026-02-09T17:10:14.37869Z","iopub.status.idle":"2026-02-09T17:10:58.184924Z","shell.execute_reply.started":"2026-02-09T17:10:14.378656Z","shell.execute_reply":"2026-02-09T17:10:58.18404Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# =========================================================\n# DENORMALIZATION (shared)\n# =========================================================\ndef denormalize(x):\n    \"\"\"\n    x: (C,H,W) or (1,C,H,W) torch tensor in normalized space\n    returns: (H,W,C) numpy in [0,1]\n    \"\"\"\n    if x.dim() == 4:\n        x = x.squeeze(0)\n    img = torch.clamp(x * STD + MEAN, 0, 1)\n    return img.detach().cpu().permute(1, 2, 0).numpy()\n\n# =========================================================\n# GENERATE ADVERSARIALS (ONCE)\n# =========================================================\nlazy_adv, lazy_grad = generate_cw(\n    lazy_model, images, labels, targeted=True\n)\n\nrobust_adv, robust_grad = generate_cw(\n    robust_model, images, labels, targeted=True\n)\n\n# =========================================================\n# VIS CONFIG\n# =========================================================\nN_VIZ = 8  # number of samples to visualize (same for all phases)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T20:51:03.763376Z","iopub.execute_input":"2026-02-08T20:51:03.763585Z","iopub.status.idle":"2026-02-08T20:51:35.994971Z","shell.execute_reply.started":"2026-02-08T20:51:03.763566Z","shell.execute_reply":"2026-02-08T20:51:35.994364Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axs = plt.subplots(3, N_VIZ, figsize=(18, 8))\n\nfor i in range(N_VIZ):\n    # Original\n    axs[0, i].imshow(denormalize(images[i]))\n    axs[0, i].axis(\"off\")\n\n    # Lazy model adversarial\n    axs[1, i].imshow(denormalize(lazy_adv[i]))\n    axs[1, i].axis(\"off\")\n\n    # IRM model adversarial\n    axs[2, i].imshow(denormalize(robust_adv[i]))\n    axs[2, i].axis(\"off\")\n\n# Row labels\naxs[0, 0].set_ylabel(\"Original\", fontsize=12)\naxs[1, 0].set_ylabel(\"Lazy (ERM)\", fontsize=12)\naxs[2, 0].set_ylabel(\"IRM (Robust)\", fontsize=12)\n\nplt.suptitle(\n    f\"Phase 0 — Original vs Adversarial (Lazy vs IRM) | ε = {EPSILON}\",\n    fontsize=14\n)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T20:51:35.995814Z","iopub.execute_input":"2026-02-08T20:51:35.996047Z","iopub.status.idle":"2026-02-08T20:51:36.270998Z","shell.execute_reply.started":"2026-02-08T20:51:35.996026Z","shell.execute_reply":"2026-02-08T20:51:36.2704Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axs = plt.subplots(2, N_VIZ, figsize=(18, 5))\n\nfor i in range(N_VIZ):\n    orig = denormalize(images[i])\n\n    # Lazy perturbation\n    lazy_adv_img = denormalize(lazy_adv[i])\n    lazy_delta = np.abs(lazy_adv_img - orig)\n    lazy_delta_viz = np.clip(lazy_delta * 100, 0, 1)\n\n    # IRM perturbation\n    robust_adv_img = denormalize(robust_adv[i])\n    robust_delta = np.abs(robust_adv_img - orig)\n    robust_delta_viz = np.clip(robust_delta * 100, 0, 1)\n\n    axs[0, i].imshow(lazy_delta_viz)\n    axs[0, i].axis(\"off\")\n\n    axs[1, i].imshow(robust_delta_viz)\n    axs[1, i].axis(\"off\")\n\n# Row labels\naxs[0, 0].set_ylabel(\"|Δ| Lazy\", fontsize=12)\naxs[1, 0].set_ylabel(\"|Δ| IRM\", fontsize=12)\n\nplt.suptitle(\n    f\"Absolute Perturbation |Δ| (×100) | Lazy vs IRM | ε = {EPSILON}\",\n    fontsize=14\n)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T20:51:36.271872Z","iopub.execute_input":"2026-02-08T20:51:36.27212Z","iopub.status.idle":"2026-02-08T20:51:36.459528Z","shell.execute_reply.started":"2026-02-08T20:51:36.272097Z","shell.execute_reply":"2026-02-08T20:51:36.458998Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axs = plt.subplots(2, N_VIZ, figsize=(18, 7))\n\nfor i in range(N_VIZ):\n    orig = denormalize(images[i])\n\n    # ----- Lazy model -----\n    lazy_adv_img = denormalize(lazy_adv[i])\n    lazy_delta = lazy_adv_img - orig\n    lazy_heat = np.linalg.norm(lazy_delta, axis=2)\n    lazy_heat = lazy_heat / (lazy_heat.max() + 1e-8)\n\n    axs[0, i].imshow(orig)\n    axs[0, i].imshow(lazy_heat, cmap=\"jet\", alpha=0.5)\n    axs[0, i].axis(\"off\")\n\n    # ----- IRM model -----\n    robust_adv_img = denormalize(robust_adv[i])\n    robust_delta = robust_adv_img - orig\n    robust_heat = np.linalg.norm(robust_delta, axis=2)\n    robust_heat = robust_heat / (robust_heat.max() + 1e-8)\n\n    axs[1, i].imshow(orig)\n    axs[1, i].imshow(robust_heat, cmap=\"jet\", alpha=0.5)\n    axs[1, i].axis(\"off\")\n\n# Row labels\naxs[0, 0].set_ylabel(\"Lazy (ERM)\", fontsize=12)\naxs[1, 0].set_ylabel(\"IRM (Robust)\", fontsize=12)\n\nplt.suptitle(\n    f\"Spatial Perturbation Heatmap | Lazy vs IRM | ε = {EPSILON}\",\n    fontsize=14\n)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T20:51:36.461005Z","iopub.execute_input":"2026-02-08T20:51:36.461291Z","iopub.status.idle":"2026-02-08T20:51:36.722043Z","shell.execute_reply.started":"2026-02-08T20:51:36.46127Z","shell.execute_reply":"2026-02-08T20:51:36.721156Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def collect_deltas(orig, adv):\n    return (adv - orig).reshape(-1)\n\nlazy_deltas = []\nrobust_deltas = []\n\nfor i in range(len(images)):\n    orig = denormalize(images[i])\n\n    lazy_adv_img = denormalize(lazy_adv[i])\n    robust_adv_img = denormalize(robust_adv[i])\n\n    lazy_deltas.append(collect_deltas(orig, lazy_adv_img))\n    robust_deltas.append(collect_deltas(orig, robust_adv_img))\n\nlazy_deltas = np.concatenate(lazy_deltas)\nrobust_deltas = np.concatenate(robust_deltas)\n\n# Symmetric range for fair comparison\nmax_range = max(\n    np.abs(lazy_deltas).max(),\n    np.abs(robust_deltas).max()\n)\n\nbins = np.linspace(-max_range, max_range, 200)\n\nplt.figure(figsize=(8, 5))\nplt.hist(\n    lazy_deltas, bins=bins, alpha=0.6,\n    label=\"Lazy (ERM)\", density=True\n)\nplt.hist(\n    robust_deltas, bins=bins, alpha=0.6,\n    label=\"IRM (Robust)\", density=True\n)\n\nplt.xlabel(\"Perturbation value (signed)\")\nplt.ylabel(\"Density\")\nplt.title(f\"Perturbation Value Distribution | ε = {EPSILON}\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T20:51:36.723036Z","iopub.execute_input":"2026-02-08T20:51:36.723478Z","iopub.status.idle":"2026-02-08T20:51:37.641426Z","shell.execute_reply.started":"2026-02-08T20:51:36.723455Z","shell.execute_reply":"2026-02-08T20:51:37.640796Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axs = plt.subplots(4, N_VIZ, figsize=(18, 12))\n\nfor i in range(N_VIZ):\n    orig = denormalize(images[i])\n\n    # ===== Lazy model =====\n    lazy_grad_img = lazy_grad[i].detach().cpu().permute(1, 2, 0).numpy()\n    lazy_grad_mag = np.linalg.norm(lazy_grad_img, axis=2)\n\n    lazy_adv_img = denormalize(lazy_adv[i])\n    lazy_delta_mag = np.linalg.norm(lazy_adv_img - orig, axis=2)\n\n    axs[0, i].imshow(lazy_grad_mag, cmap=\"magma\")\n    axs[0, i].axis(\"off\")\n\n    axs[1, i].imshow(lazy_delta_mag, cmap=\"inferno\")\n    axs[1, i].axis(\"off\")\n\n    # ===== IRM model =====\n    robust_grad_img = robust_grad[i].detach().cpu().permute(1, 2, 0).numpy()\n    robust_grad_mag = np.linalg.norm(robust_grad_img, axis=2)\n\n    robust_adv_img = denormalize(robust_adv[i])\n    robust_delta_mag = np.linalg.norm(robust_adv_img - orig, axis=2)\n\n    axs[2, i].imshow(robust_grad_mag, cmap=\"magma\")\n    axs[2, i].axis(\"off\")\n\n    axs[3, i].imshow(robust_delta_mag, cmap=\"inferno\")\n    axs[3, i].axis(\"off\")\n\n# Row labels\naxs[0, 0].set_ylabel(\"‖∇x L‖\\nLazy\", fontsize=12)\naxs[1, 0].set_ylabel(\"‖Δ‖\\nLazy\", fontsize=12)\naxs[2, 0].set_ylabel(\"‖∇x L‖\\nIRM\", fontsize=12)\naxs[3, 0].set_ylabel(\"‖Δ‖\\nIRM\", fontsize=12)\n\nplt.suptitle(\n    f\"Gradients(what model is sensitive to) vs Perturbations(what model changed) | Lazy vs IRM | ε = {EPSILON}\",\n    fontsize=14\n)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T20:51:37.642327Z","iopub.execute_input":"2026-02-08T20:51:37.642581Z","iopub.status.idle":"2026-02-08T20:51:38.146665Z","shell.execute_reply.started":"2026-02-08T20:51:37.642559Z","shell.execute_reply":"2026-02-08T20:51:38.145964Z"}},"outputs":[],"execution_count":null}]}