{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14760510,"sourceType":"datasetVersion","datasetId":9434511},{"sourceId":745111,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":568438,"modelId":580771}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nTask 4: The Intervention - Method 4: Gradient Reversal Layer (GRL)\n\nAdversarial approach that forces the network to learn color-invariant features\nby adding a \"color predictor\" head with reversed gradients.\n\"\"\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport os\n\n# ==============================================================================\n# Configuration & Hyperparameters\n# ==============================================================================\nclass Config:\n    # Data Paths\n    DATA_DIR = r\"/kaggle/input/cmnistneo1\"\n    TRAIN_FILE = \"train_data_rg95z.npz\"\n    TEST_FILE = \"test_data_gr95z.npz\"\n    # Training Hyperparameters\n    BATCH_SIZE = 128\n    EPOCHS = 20\n    LR = 1e-3\n    WEIGHT_DECAY = 1e-4\n    \n    # GRL Specifics\n    GRL_LAMBDA = 1.0  # Strength of gradient reversal\n    \n    # System\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    SEED = 42\n\n# ==============================================================================\n# Gradient Reversal Layer\n# ==============================================================================\nclass GradientReversalFunction(torch.autograd.Function):\n    \"\"\"\n    During forward pass: identity (no change)\n    During backward pass: flip the gradient sign\n    \"\"\"\n    @staticmethod\n    def forward(ctx, x, lambda_):\n        ctx.lambda_ = lambda_\n        return x.view_as(x)\n    \n    @staticmethod\n    def backward(ctx, grad_output):\n        return grad_output.neg() * ctx.lambda_, None\n\nclass GradientReversalLayer(nn.Module):\n    def __init__(self, lambda_=1.0):\n        super(GradientReversalLayer, self).__init__()\n        self.lambda_ = lambda_\n    \n    def forward(self, x):\n        return GradientReversalFunction.apply(x, self.lambda_)\n\n# ==============================================================================\n# Model Architecture with GRL\n# ==============================================================================\nclass CNNWithGRL(nn.Module):\n    def __init__(self, num_classes=10, num_colors=3, grl_lambda=1.0):\n        super(CNNWithGRL, self).__init__()\n        \n        # Shared feature extractor\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            \n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            \n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2)\n        )\n        \n        # Main classifier (for digits)\n        self.digit_classifier = nn.Sequential(\n            nn.Linear(64 * 3 * 3, 128),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(128, num_classes)\n        )\n        \n        # Gradient Reversal Layer\n        self.grl = GradientReversalLayer(lambda_=grl_lambda)\n        \n        # Color discriminator (adversarial head)\n        self.color_discriminator = nn.Sequential(\n            nn.Linear(64 * 3 * 3, 64),\n            nn.ReLU(),\n            nn.Linear(64, num_colors)\n        )\n\n    def forward(self, x):\n        # Shared features\n        features = self.features(x)\n        features_flat = features.reshape(features.size(0), -1)\n        \n        # Digit prediction (main task)\n        digit_out = self.digit_classifier(features_flat)\n        \n        # Color prediction (through GRL - adversarial)\n        reversed_features = self.grl(features_flat)\n        color_out = self.color_discriminator(reversed_features)\n        \n        return digit_out, color_out\n\n# ==============================================================================\n# Utils: Data Loading\n# ==============================================================================\ndef get_dominant_color(img_tensor):\n    \"\"\"Returns dominant channel index (0=R, 1=G, 2=B).\"\"\"\n    means = torch.mean(img_tensor, dim=(1, 2))\n    return torch.argmax(means).item()\n\ndef load_data(config):\n    \"\"\"Loads data with color labels.\"\"\"\n    print(f\"\\n[Data] Loading from {config.DATA_DIR}...\")\n    \n    train_path = os.path.join(config.DATA_DIR, config.TRAIN_FILE)\n    train_data = np.load(train_path)\n    X_train = torch.tensor(train_data['images'].astype('float32') / 255.0).permute(0, 3, 1, 2)\n    y_train = torch.tensor(train_data['labels']).long()\n    \n    # Extract color labels\n    print(\"[Data] Extracting color labels...\")\n    color_labels = []\n    for i in range(len(X_train)):\n        color_labels.append(get_dominant_color(X_train[i]))\n    color_train = torch.tensor(color_labels).long()\n    \n    # Load Test\n    test_path = os.path.join(config.DATA_DIR, config.TEST_FILE)\n    test_data = np.load(test_path)\n    X_test = torch.tensor(test_data['images'].astype('float32') / 255.0).permute(0, 3, 1, 2)\n    y_test = torch.tensor(test_data['labels']).long()\n    \n    print(f\"  Train: {X_train.shape}, Colors: {color_train.shape}\")\n    print(f\"  Test: {X_test.shape}\")\n    \n    ds_train = TensorDataset(X_train, y_train, color_train)\n    ds_test = TensorDataset(X_test, y_test)\n    \n    return ds_train, ds_test\n\n# ==============================================================================\n# Training Loop with GRL\n# ==============================================================================\ndef train(config):\n    torch.manual_seed(config.SEED)\n    \n    # Load Data\n    ds_train, ds_test = load_data(config)\n    \n    # Loaders\n    loader_train = DataLoader(ds_train, batch_size=config.BATCH_SIZE, shuffle=True)\n    loader_test = DataLoader(ds_test, batch_size=config.BATCH_SIZE, shuffle=False)\n    \n    # Model & Optim\n    model = CNNWithGRL(grl_lambda=config.GRL_LAMBDA).to(config.DEVICE)\n    optimizer = optim.Adam(model.parameters(), lr=config.LR, weight_decay=config.WEIGHT_DECAY)\n    \n    print(f\"\\n[Train] Starting GRL Training on {config.DEVICE}...\")\n    print(f\"  GRL Lambda: {config.GRL_LAMBDA}\")\n    \n    # Track history\n    history = {'digit_loss': [], 'color_loss': [], 'test_acc': []}\n    \n    for epoch in range(config.EPOCHS):\n        model.train()\n        total_digit_loss = 0\n        total_color_loss = 0\n        correct = 0\n        total = 0\n        \n        for x, y_digit, y_color in loader_train:\n            x = x.to(config.DEVICE)\n            y_digit = y_digit.to(config.DEVICE)\n            y_color = y_color.to(config.DEVICE)\n            \n            optimizer.zero_grad()\n            \n            # Forward\n            digit_out, color_out = model(x)\n            \n            # Losses\n            digit_loss = nn.CrossEntropyLoss()(digit_out, y_digit)\n            color_loss = nn.CrossEntropyLoss()(color_out, y_color)\n            \n            # Total loss (color_loss gradient will be reversed by GRL)\n            total_loss = digit_loss + color_loss\n            \n            total_loss.backward()\n            optimizer.step()\n            \n            # Stats\n            total_digit_loss += digit_loss.item()\n            total_color_loss += color_loss.item()\n            _, preds = torch.max(digit_out, 1)\n            correct += (preds == y_digit).sum().item()\n            total += y_digit.size(0)\n        \n        # Logging\n        avg_digit_loss = total_digit_loss / len(loader_train)\n        avg_color_loss = total_color_loss / len(loader_train)\n        train_acc = 100 * correct / total\n        \n        # Evaluate\n        val_acc = evaluate(model, loader_test, config.DEVICE)\n        \n        # Store history\n        history['digit_loss'].append(avg_digit_loss)\n        history['color_loss'].append(avg_color_loss)\n        history['test_acc'].append(val_acc)\n        \n        print(f\"Epoch [{epoch+1}/{config.EPOCHS}] Digit Loss: {avg_digit_loss:.4f} | Color Loss: {avg_color_loss:.4f} | Train Acc: {train_acc:.1f}% | Test Acc: {val_acc:.2f}%\")\n\n    # Final Save\n    save_path = \"task4_grl_model.pth\"\n    torch.save(model.state_dict(), save_path)\n    print(f\"\\n[Done] Model saved to {save_path}\")\n    \n    # ========== VISUALIZATIONS ==========\n    print(\"\\n[Visualizations] Generating plots...\")\n    \n    # 1. Training History\n    plt.figure(figsize=(15, 4))\n    \n    plt.subplot(1, 3, 1)\n    plt.plot(history['digit_loss'], label='Digit Loss', linewidth=2)\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Digit Classification Loss (GRL)')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    plt.subplot(1, 3, 2)\n    plt.plot(history['color_loss'], label='Color Loss (Adversarial)', color='orange', linewidth=2)\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Color Discriminator Loss (Reversed)')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    plt.subplot(1, 3, 3)\n    plt.plot(history['test_acc'], label='Hard Test Acc', color='green', linewidth=2)\n    plt.axhline(70, color='r', linestyle='--', alpha=0.7, label='Target (70%)')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.title('Performance on Hard Test Set')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig('task4_grl_training.png', dpi=150, bbox_inches='tight')\n    print(\"  Saved: task4_grl_training.png\")\n    plt.show()\n    \n    # 2. Confusion Matrix\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for x, y in loader_test:\n            x, y = x.to(config.DEVICE), y.to(config.DEVICE)\n            digit_out, _ = model(x)\n            preds = torch.max(digit_out, 1)[1]\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(y.cpu().numpy())\n    \n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=range(10), yticklabels=range(10))\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix - GRL on Hard Test Set')\n    plt.savefig('task4_grl_confusion.png', dpi=150, bbox_inches='tight')\n    print(\"  Saved: task4_grl_confusion.png\")\n    plt.show()\n    \n    # 3. Sample Predictions\n    test_data = np.load(os.path.join(config.DATA_DIR, config.TEST_FILE))\n    X_test_np = test_data['images']\n    y_test_np = test_data['labels']\n    \n    sample_indices = np.random.choice(len(X_test_np), 10, replace=False)\n    \n    plt.figure(figsize=(15, 6))\n    for i, idx in enumerate(sample_indices):\n        img_tensor = torch.FloatTensor(X_test_np[idx:idx+1] / 255.0).permute(0, 3, 1, 2).to(config.DEVICE)\n        with torch.no_grad():\n            digit_out, color_out = model(img_tensor)\n            pred = torch.max(digit_out, 1)[1].item()\n            color_pred = torch.max(color_out, 1)[1].item()\n        true_label = y_test_np[idx]\n        \n        plt.subplot(2, 5, i+1)\n        plt.imshow(X_test_np[idx])\n        color_names = ['Red', 'Green', 'Blue']\n        plt.title(f'True: {true_label}, Pred: {pred}\\nColor: {color_names[color_pred]}', \n                 color='green' if pred == true_label else 'red', fontsize=9)\n        plt.axis('off')\n    \n    plt.suptitle('GRL: Sample Predictions (showing color confusion)', fontsize=14, y=1.02)\n    plt.tight_layout()\n    plt.savefig('task4_grl_samples.png', dpi=150, bbox_inches='tight')\n    print(\"  Saved: task4_grl_samples.png\")\n    plt.show()\n    \n    # 4. Final Summary\n    final_acc = history['test_acc'][-1]\n    print(f\"\\n{'='*60}\")\n    print(f\"FINAL RESULTS - Gradient Reversal Layer (GRL)\")\n    print(f\"{'='*60}\")\n    print(f\"Final Test Accuracy: {final_acc:.2f}%\")\n    print(f\"Target Achieved: {'✓ YES' if final_acc >= 70 else '✗ NO'}\")\n    print(f\"Best Test Accuracy: {max(history['test_acc']):.2f}% (Epoch {np.argmax(history['test_acc'])+1})\")\n    print(f\"{'='*60}\")\n\ndef evaluate(model, loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            digit_out, _ = model(x)\n            _, preds = torch.max(digit_out, 1)\n            correct += (preds == y).sum().item()\n            total += y.size(0)\n    return 100 * correct / total\n\nif __name__ == \"__main__\":\n    train(Config)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}